{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.utils.data as data_utils\n\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.io import loadmat\nfrom scipy import sparse\nimport os\n\nimport pickle\nfrom tqdm import tqdm\nimport sys\nplt.style.use('ggplot')\nimport gc\nimport warnings as w\nw.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T10:13:03.392613Z","iopub.execute_input":"2022-06-07T10:13:03.393532Z","iopub.status.idle":"2022-06-07T10:13:05.668308Z","shell.execute_reply.started":"2022-06-07T10:13:03.393433Z","shell.execute_reply":"2022-06-07T10:13:05.666741Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing :https://www.kaggle.com/code/leejunseok97/evcf-sota-model-rc-preprocess","metadata":{}},{"cell_type":"markdown","source":"# now Incomplete","metadata":{}},{"cell_type":"code","source":"!pip install bottleneck","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:05.676265Z","iopub.execute_input":"2022-06-07T10:13:05.681175Z","iopub.status.idle":"2022-06-07T10:13:20.293338Z","shell.execute_reply.started":"2022-06-07T10:13:05.681110Z","shell.execute_reply":"2022-06-07T10:13:20.292271Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bottleneck\n  Downloading Bottleneck-1.3.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_24_x86_64.whl (332 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.6/332.6 kB\u001b[0m \u001b[31m570.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bottleneck) (1.21.6)\nInstalling collected packages: bottleneck\nSuccessfully installed bottleneck-1.3.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## EVCF(Enhancing VAEs for collaborative Filtering)\n### Github Link : https://github.com/psywaves/EVCF","metadata":{}},{"cell_type":"code","source":"def load_train_data(csv_file):\n    unique_sid = list()\n    with open('../input/sid-data/unique_sid.txt','r') as f:\n        for line in f:\n            unique_sid.append(line.strip())\n    tp = pd.read_csv(csv_file)\n    n_users = tp['uid'].max() + 1\n    n_items = len(unique_sid)\n\n    rows, cols = tp['uid'], tp['sid']\n    data = sparse.csr_matrix((np.ones_like(rows),\n                                  (rows, cols)), dtype='float32',\n                                 shape=(n_users, n_items)).toarray()\n    return data\n\ndef load_tr_te_data(csv_file_tr, csv_file_te):\n    unique_sid = list()\n    with open('../input/sid-data/unique_sid.txt','r') as f:\n        for line in f:\n            unique_sid.append(line.strip())\n    n_items = len(unique_sid)\n    tp_tr = pd.read_csv(csv_file_tr)\n    tp_te = pd.read_csv(csv_file_te)\n\n    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n\n    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n\n    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),(rows_tr, cols_tr)),\n                                    dtype='float32', shape=(end_idx - start_idx + 1, n_items)).toarray()\n    data_te = sparse.csr_matrix((np.ones_like(rows_te),(rows_te, cols_te)),\n                                    dtype='float32', shape=(end_idx - start_idx + 1, n_items)).toarray()\n    return data_tr, data_te","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:20.295664Z","iopub.execute_input":"2022-06-07T10:13:20.296165Z","iopub.status.idle":"2022-06-07T10:13:20.309846Z","shell.execute_reply.started":"2022-06-07T10:13:20.296115Z","shell.execute_reply":"2022-06-07T10:13:20.308757Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"x_train = load_train_data(os.path.join(\"../input/netflix-preprocess\", 'train (3).csv'))\nnp.random.shuffle(x_train)\nx_val_tr, x_val_te = load_tr_te_data(os.path.join(\"../input/netflix-preprocess\", 'validation_tr.csv'),\n                                         os.path.join(\"../input/netflix-preprocess\", 'validation_te.csv'))\n\nx_test_tr, x_test_te = load_tr_te_data(os.path.join(\"../input/netflix-preprocess\", 'test_tr.csv'),\n                                           os.path.join(\"../input/netflix-preprocess\", 'test_te.csv'))\n\n# idle y's\ny_train = np.zeros((x_train.shape[0], 1))\n\n\n# pytorch data loader\ntrain = data_utils.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\ntrain_loader = data_utils.DataLoader(train, batch_size=512, shuffle=True)\n\nvalidation = data_utils.TensorDataset(torch.from_numpy(x_val_tr), torch.from_numpy(x_val_te))\nval_loader = data_utils.DataLoader(validation, batch_size=512, shuffle=False)\n\ntest = data_utils.TensorDataset(torch.from_numpy(x_test_tr).float(), torch.from_numpy(x_test_te))\ntest_loader = data_utils.DataLoader(test, batch_size=512, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:20.312793Z","iopub.execute_input":"2022-06-07T10:13:20.313372Z","iopub.status.idle":"2022-06-07T10:13:35.426235Z","shell.execute_reply.started":"2022-06-07T10:13:20.313329Z","shell.execute_reply":"2022-06-07T10:13:35.425365Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data,label = next(iter(train_loader))\nprint(data.shape,label.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.427689Z","iopub.execute_input":"2022-06-07T10:13:35.428096Z","iopub.status.idle":"2022-06-07T10:13:35.475884Z","shell.execute_reply.started":"2022-06-07T10:13:35.428057Z","shell.execute_reply":"2022-06-07T10:13:35.474700Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"torch.Size([512, 4497]) torch.Size([512, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"sys.path.insert(0,os.path.abspath('../input/-utils'))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.477805Z","iopub.execute_input":"2022-06-07T10:13:35.478303Z","iopub.status.idle":"2022-06-07T10:13:35.484669Z","shell.execute_reply.started":"2022-06-07T10:13:35.478255Z","shell.execute_reply":"2022-06-07T10:13:35.483628Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sys.path","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.486842Z","iopub.execute_input":"2022-06-07T10:13:35.487966Z","iopub.status.idle":"2022-06-07T10:13:35.502881Z","shell.execute_reply.started":"2022-06-07T10:13:35.487916Z","shell.execute_reply":"2022-06-07T10:13:35.501511Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/-utils',\n '/kaggle/working',\n '/kaggle/lib/kagglegym',\n '/kaggle/lib',\n '/opt/conda/lib/python37.zip',\n '/opt/conda/lib/python3.7',\n '/opt/conda/lib/python3.7/lib-dynload',\n '',\n '/root/.local/lib/python3.7/site-packages',\n '/opt/conda/lib/python3.7/site-packages',\n '/src/bq-helper',\n '/opt/conda/lib/python3.7/site-packages/IPython/extensions',\n '/root/.ipython']"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.utils.data\nimport torch.nn as nn\nfrom torch.nn import Linear\nfrom torch.autograd import Variable\nfrom torch.nn.functional import normalize\n\nfrom Optimizer import AdamNormGrad\nimport bottleneck as bn\nfrom nn import he_init, GatedDense, NonLinear\nfrom distribution import log_Bernoulli, log_Normal_diag, log_Normal_standard, log_Logistic_256, log_Softmax","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.505340Z","iopub.execute_input":"2022-06-07T10:13:35.506219Z","iopub.status.idle":"2022-06-07T10:13:35.533486Z","shell.execute_reply.started":"2022-06-07T10:13:35.506150Z","shell.execute_reply":"2022-06-07T10:13:35.532602Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,input_size=[1,28,28],number_components=1000,\n                 pseudoinputs_mean=0.05,pseudoinputs_std=0.01,use_training_data_init=False):\n        super(Model, self).__init__()\n        self.input_size = input_size\n        self.number_components = number_components\n        self.pseudoinputs_mean = pseudoinputs_mean\n        self.pseudoinputs_std = pseudoinputs_std\n        self.use_training_data_init = use_training_data_init\n    # AUXILIARY METHODS\n    def add_pseudoinputs(self):\n\n        nonlinearity = nn.Hardtanh(min_val=0.0, max_val=1.0)\n\n        self.means = NonLinear(self.number_components, np.prod(self.input_size), bias=False, activation=nonlinearity)\n\n        # init pseudo-inputs\n        if self.use_training_data_init:\n            self.means.linear.weight.data = self.pseudoinputs_mean\n        else:\n            normal_init(self.means.linear, self.pseudoinputs_mean, self.pseudoinputs_std)\n\n        # create an idle input for calling pseudo-inputs\n        self.idle_input = Variable(torch.eye(self.number_components, self.number_components), requires_grad=False)\n        \n    def reparameterize(self, mu, logvar):\n        if self.training:\n            std = logvar.mul(0.5).exp_()\n            \n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n            \n            eps = Variable(eps)\n            return eps.mul(std).add_(mu)\n        else:\n            return mu\n\n    def calculate_loss(self):\n        return 0.\n\n    def calculate_likelihood(self):\n        return 0.\n\n    def calculate_lower_bound(self):\n        return 0.\n\n    # THE MODEL: FORWARD PASS\n    def forward(self, x):\n        return 0.\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.535179Z","iopub.execute_input":"2022-06-07T10:13:35.535613Z","iopub.status.idle":"2022-06-07T10:13:35.548360Z","shell.execute_reply.started":"2022-06-07T10:13:35.535577Z","shell.execute_reply":"2022-06-07T10:13:35.547086Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class VAE(Model):\n    def __init__(self,input_size,hidden_size,gated,num_layers,z1_size):\n        super(VAE,self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.gated = gated\n        self.num_layers = num_layers\n        self.z1_size = z1_size\n        modules = [\n            nn.Dropout(0.5),\n            NonLinear(np.prod(self.input_size), self.hidden_size, \n                      gated=self.gated,activation=nn.Tanh())\n        ]\n        for _ in range(0, self.num_layers - 1):\n            modules.append(\n                NonLinear(self.hidden_size,self.hidden_size,\n                        gated=self.gated,activation=nn.Tanh()))\n        self.q_z_layers = nn.Sequential(*modules)\n        \n        self.q_z_mean = Linear(self.hidden_size,self.z1_size)\n        self.q_z_logvar = NonLinear(self.hidden_size,self.z1_size,\n                                    activation=nn.Hardtanh(min_val=-12.,max_val=4.))\n        \n        \n        modules = [NonLinear(self.z1_size,self.hidden_size,\n                             gated=self.gated,activation=nn.Tanh())]\n        for _ in range(0,self.num_layers - 1):\n            modules.append(\n                NonLinear(self.hidden_size,self.hidden_size,\n                          gated=self.gated,activation=nn.Tanh()))\n        self.p_x_layers = nn.Sequential(*modules)\n        \n        self.p_x_mean = NonLinear(self.hidden_size,np.prod(self.input_size),\n                                 activation=None)\n        \n        for m in self.modules():\n            if isinstance(m,nn.Linear):\n                he_init(m)\n                \n    def calculate_loss(self,x,beta=1.,average=False):\n        \n        x_mean, x_logvar, z_q, z_q_mean, z_q_logvar = self.forward(x)\n        \n        RE = log_Softmax(x,x_mean,dim=1)\n        \n        \n        log_p_z = self.log_p_z(z_q)\n        log_q_z = log_Normal_diag(z_q, z_q_mean, z_q_logvar,dim=1)\n        KL = -(log_p_z - log_q_z)\n        \n        loss = -RE + beta * KL\n        \n        if average:\n            loss = torch.mean(loss)\n            RE = torch.mean(RE)\n            KL = torch.mean(KL)\n            \n        return loss, RE, KL\n    \n    def reconstruct_x(self,x):\n        x_mean, _, _, _, _ = self.forward(x)\n        return x_mean\n    \n    def q_z(self,x):\n        x = self.q_z_layers(x)\n        \n        z_q_mean = self.q_z_mean(x)\n        z_q_logvar = self.q_z_logvar(x)\n        \n        return z_q_mean, z_q_logvar\n    \n    def p_x(self,z):\n        z = self.p_x_layers(z)\n        \n        x_mean = self.p_x_mean(z)\n        x_logvar = 0\n        \n        return x_mean, x_logvar\n    \n    def log_p_z(self,z):\n        log_prior = log_Normal_standard(z,dim=1)\n        \n        return log_prior\n    \n    def forward(self,x):\n        \n        x = normalize(x,dim=1)\n        \n        z_q_mean, z_q_logvar = self.q_z(x)\n        \n        z_q = self.reparameterize(z_q_mean,z_q_logvar)\n        \n        x_mean, x_logvar = self.p_x(z_q)\n        \n        return x_mean, x_logvar, z_q, z_q_mean, z_q_logvar\n                           ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.552052Z","iopub.execute_input":"2022-06-07T10:13:35.553048Z","iopub.status.idle":"2022-06-07T10:13:35.579243Z","shell.execute_reply.started":"2022-06-07T10:13:35.553002Z","shell.execute_reply":"2022-06-07T10:13:35.577913Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 512\nepoch = 400\nlr = 5e-3\nwarmup = 100\nmax_beta = 1\n\nnum_layers = 1\nz1_size = 200\nz2_size = 200\nhidden_size = 600\ninput_size = 4497\ndevice = ('cuda' if torch.cuda.is_available() else 'cpu')\nmode = 'train'","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.580878Z","iopub.execute_input":"2022-06-07T10:13:35.581741Z","iopub.status.idle":"2022-06-07T10:13:35.645760Z","shell.execute_reply.started":"2022-06-07T10:13:35.581696Z","shell.execute_reply":"2022-06-07T10:13:35.644421Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = VAE(input_size=input_size,hidden_size=hidden_size,gated=True,\n            num_layers=num_layers,z1_size=z1_size)\noptimizer = AdamNormGrad(model.parameters(),lr=lr)\nmodel.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:35.647661Z","iopub.execute_input":"2022-06-07T10:13:35.648137Z","iopub.status.idle":"2022-06-07T10:13:38.842911Z","shell.execute_reply.started":"2022-06-07T10:13:35.648092Z","shell.execute_reply":"2022-06-07T10:13:38.842053Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"VAE(\n  (q_z_layers): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): NonLinear(\n      (activation): Tanh()\n      (linear): Linear(in_features=4497, out_features=600, bias=True)\n      (sigmoid): Sigmoid()\n      (g): Linear(in_features=4497, out_features=600, bias=True)\n    )\n  )\n  (q_z_mean): Linear(in_features=600, out_features=200, bias=True)\n  (q_z_logvar): NonLinear(\n    (activation): Hardtanh(min_val=-12.0, max_val=4.0)\n    (linear): Linear(in_features=600, out_features=200, bias=True)\n  )\n  (p_x_layers): Sequential(\n    (0): NonLinear(\n      (activation): Tanh()\n      (linear): Linear(in_features=200, out_features=600, bias=True)\n      (sigmoid): Sigmoid()\n      (g): Linear(in_features=200, out_features=600, bias=True)\n    )\n  )\n  (p_x_mean): NonLinear(\n    (linear): Linear(in_features=600, out_features=4497, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def NDCG_binary_at_k_batch(X_pred, heldout_batch,k=100):\n    batch_users = X_pred.shape[0]\n    idx_topk_part = bn.argpartition(-X_pred,k,axis=1)\n    topk_part = X_pred[np.arange(batch_users)[:,np.newaxis],idx_topk_part[:,:k]]\n    idx_part = np.argsort(-topk_part, axis=1)\n    \n    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis],idx_part]\n    tp = 1. / np.log2(np.arange(2,k+2))\n    tp = torch.tensor(tp,dtype=torch.float)\n    \n    DCG = (heldout_batch[np.arange(batch_users)[:,np.newaxis],idx_topk].cpu() * tp).sum(dim=1)\n    \n    IDCG = torch.tensor([(tp[:min(n,k)]).sum() for n in (heldout_batch != 0).sum(dim=1)])\n    \n    return DCG / IDCG\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:38.848161Z","iopub.execute_input":"2022-06-07T10:13:38.851896Z","iopub.status.idle":"2022-06-07T10:13:38.867308Z","shell.execute_reply.started":"2022-06-07T10:13:38.851849Z","shell.execute_reply":"2022-06-07T10:13:38.866391Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def Recall_at_k_batch(X_pred,heldout_batch,k=100):\n    batch_users = X_pred.shape[0]\n    \n    idx = bn.argpartition(-X_pred,k,axis=1)\n    X_pred_binary = np.zeros_like(X_pred,dtype=bool)\n    X_pred_binary[np.arange(batch_users)[:,np.newaxis], idx[:,:k]] = True\n    \n    X_true_binary = torch.tensor((heldout_batch > 0),dtype=torch.float)\n    tmp = torch.tensor(np.logical_and(X_true_binary,X_pred_binary),dtype=torch.float).sum(dim=1)\n    recall = tmp / np.minimum(k,X_true_binary.sum(dim=1))\n    return recall","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:38.873628Z","iopub.execute_input":"2022-06-07T10:13:38.874327Z","iopub.status.idle":"2022-06-07T10:13:38.890598Z","shell.execute_reply.started":"2022-06-07T10:13:38.874282Z","shell.execute_reply":"2022-06-07T10:13:38.889664Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for e in range(epoch):\n    train_loss = 0\n    train_re = 0\n    train_kl = 0\n    \n    valid_loss = 0\n    valid_re = 0\n    valid_kl = 0\n    \n    model.train()\n    \n    if warmup == 0:\n        beta = max_beta\n    else:\n        beta = max_beta * epoch / warmup\n        if beta > max_beta:\n            beta = max_beta\n    print(f'beta: {beta}')\n    \n    for batch_idx, (data,target) in tqdm(enumerate(train_loader)):\n        data, target = data.to(device), target.to(device)\n        data, target = Variable(data), Variable(target)\n        \n        optimizer.zero_grad()\n        \n        loss, RE, KL = model.calculate_loss(data,beta,average=True)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.data.item()\n        train_re += -RE.data.item()\n        train_kl += KL.data.item()\n    train_loss /= len(train_loader)\n    train_re /= len(train_loader)\n    train_kl /= len(train_loader)\n    \n    \n    ndcg_dist = torch.tensor([],dtype=torch.float)\n#     if mode == 'test':\n#         ndcg_20 = torch.tensor([], dtype=torch.float)\n#         ndcg_10 = torch.tensor([], dtype=torch.float)\n#         recall_50 = torch.tensor([], dtype=torch.float)\n#         recall_20 = torch.tensor([], dtype=torch.float)\n#         recall_10 = torch.tensor([], dtype=torch.float)\n#         recall_5 = torch.tensor([], dtype=torch.float)\n#         recall_1 = torch.tensor([], dtype=torch.float)\n    model.eval()\n        \n    for batch_idx, (valid_tr,valid_te) in tqdm(enumerate(val_loader)):\n        valid_tr, valid_te = valid_tr.to(device), valid_te.to(device)\n        \n        valid_tr, valid_te = Variable(valid_tr), Variable(valid_te)\n        \n        with torch.no_grad():\n            loss , RE, KL = model.calculate_loss(valid_tr,average=True)\n            \n            valid_loss += loss.data.item()\n            valid_re = -RE.data.item()\n            valid_kl = KL.data.item()\n            \n            \n            pred_val = model.reconstruct_x(valid_tr).detach().cpu().numpy()\n            \n            valid_tr = valid_tr.detach().cpu().numpy()\n            \n            pred_val[valid_tr.nonzero()] = -np.Inf\n            \n            ndcg_dist = torch.cat([ndcg_dist, NDCG_binary_at_k_batch(pred_val, valid_te,k=100)])\n            \n            \n#             if mode == 'test':\n#                 ndcg_20 = torch.cat([ndcg_20, NDCG_binary_at_k_batch(pred_val, test, k=20)])\n#                 ndcg_10 = torch.cat([ndcg_10, NDCG_binary_at_k_batch(pred_val, test, k=10)])\n#                 recall_50 = torch.cat([recall_50, Recall_at_k_batch(pred_val, test, k=50)])\n#                 recall_20 = torch.cat([recall_20, Recall_at_k_batch(pred_val, test, k=20)])\n#                 recall_10 = torch.cat([recall_10, Recall_at_k_batch(pred_val, test, k=10)])\n#                 recall_5 = torch.cat([recall_5, Recall_at_k_batch(pred_val, test, k=5)])\n#                 recall_1 = torch.cat([recall_1, Recall_at_k_batch(pred_val, test, k=1)])\n        valid_loss /= len(val_loader)\n        valid_re /= len(val_loader)\n        valid_kl /= len(val_loader)\n        \n        evaluate_ndcg = ndcg_dist.mean().data.item()\n        \n        \n#         if mode == 'test':\n#             eval_ndcg100 = \"{:.5f}({:.4f})\".format(evaluate_ndcg, ndcg_dist.std().data.item()/np.sqrt(len(ndcg_dist)))\n#             eval_ndcg20 = \"{:.5f}({:.4f})\".format(ndcg_20.mean().data.item(),ndcg_20.std().data.item()/np.sqrt(len(ndcg_20)))\n#             eval_ndcg10 = \"{:.5f}({:.4f})\".format(ndcg_10.mean().data.item(),ndcg_10.std().data.item()/np.sqrt(len(ndcg_10)))\n#             eval_recall50 = \"{:.5f}({:.4f})\".format(recall_50.mean().data.item(),recall_50.std().data.item()/np.sqrt(len(recall_50)))\n#             eval_recall20 = \"{:.5f}({:.4f})\".format(recall_20.mean().data.item(),recall_20.std().data.item()/np.sqrt(len(recall_20)))\n#             eval_recall10 = \"{:.5f}({:.4f})\".format(recall_10.mean().data.item(),recall_10.std().data.item()/np.sqrt(len(recall_10)))\n#             eval_recall5 = \"{:.5f}({:.4f})\".format(recall_5.mean().data.item(),recall_5.std().data.item()/np.sqrt(len(recall_5)))\n#             eval_recall1 = \"{:.5f}({:.4f})\".format(recall_1.mean().data.item(),recall_1.std().data.item()/np.sqrt(len(recall_1)))\n    print('Epoch:{} Train_Loss:{:.3f}\\tTrain RE:{:.3f}\\tTrain KL:{:.3f}'.format(e+1,train_loss,train_re,train_kl))\n    print('Epoch:{} Valid_Loss:{:.3f}\\tValid RE:{:.3f}\\tValid KL:{:.3f}'.format(e+1,valid_loss,valid_re,valid_kl))\n            ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:13:49.158715Z","iopub.execute_input":"2022-06-07T10:13:49.159103Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"beta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:09, 57.61it/s]\n79it [00:08,  9.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:1 Train_Loss:238.007\tTrain RE:232.779\tTrain KL:5.228\nEpoch:1 Valid_Loss:2.900\tValid RE:2.758\tValid KL:0.111\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 67.23it/s]\n79it [00:07,  9.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:2 Train_Loss:231.122\tTrain RE:225.334\tTrain KL:5.788\nEpoch:2 Valid_Loss:2.874\tValid RE:2.730\tValid KL:0.114\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 65.67it/s]\n79it [00:08,  9.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:3 Train_Loss:230.238\tTrain RE:224.295\tTrain KL:5.944\nEpoch:3 Valid_Loss:2.865\tValid RE:2.724\tValid KL:0.111\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 65.41it/s]\n79it [00:07,  9.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:4 Train_Loss:229.737\tTrain RE:223.649\tTrain KL:6.088\nEpoch:4 Valid_Loss:2.861\tValid RE:2.714\tValid KL:0.116\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 63.66it/s]\n79it [00:07, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:5 Train_Loss:229.432\tTrain RE:223.213\tTrain KL:6.219\nEpoch:5 Valid_Loss:2.864\tValid RE:2.714\tValid KL:0.119\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 68.02it/s]\n79it [00:07, 10.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:6 Train_Loss:229.250\tTrain RE:223.001\tTrain KL:6.249\nEpoch:6 Valid_Loss:2.861\tValid RE:2.712\tValid KL:0.119\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 65.63it/s]\n79it [00:08,  9.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:7 Train_Loss:229.126\tTrain RE:222.848\tTrain KL:6.279\nEpoch:7 Valid_Loss:2.859\tValid RE:2.711\tValid KL:0.117\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 67.16it/s]\n79it [00:07, 10.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:8 Train_Loss:229.053\tTrain RE:222.769\tTrain KL:6.285\nEpoch:8 Valid_Loss:2.862\tValid RE:2.708\tValid KL:0.123\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 63.88it/s]\n79it [00:07,  9.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:9 Train_Loss:228.955\tTrain RE:222.651\tTrain KL:6.305\nEpoch:9 Valid_Loss:2.858\tValid RE:2.711\tValid KL:0.116\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 66.87it/s]\n79it [00:07, 10.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:10 Train_Loss:228.986\tTrain RE:222.685\tTrain KL:6.301\nEpoch:10 Valid_Loss:2.862\tValid RE:2.709\tValid KL:0.122\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 64.93it/s]\n79it [00:07,  9.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:11 Train_Loss:228.888\tTrain RE:222.572\tTrain KL:6.315\nEpoch:11 Valid_Loss:2.862\tValid RE:2.708\tValid KL:0.123\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 66.50it/s]\n79it [00:07, 10.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:12 Train_Loss:228.796\tTrain RE:222.472\tTrain KL:6.323\nEpoch:12 Valid_Loss:2.859\tValid RE:2.708\tValid KL:0.121\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 65.36it/s]\n79it [00:07, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:13 Train_Loss:228.756\tTrain RE:222.429\tTrain KL:6.327\nEpoch:13 Valid_Loss:2.864\tValid RE:2.709\tValid KL:0.124\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 67.48it/s]\n79it [00:07, 10.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:14 Train_Loss:228.721\tTrain RE:222.388\tTrain KL:6.333\nEpoch:14 Valid_Loss:2.861\tValid RE:2.708\tValid KL:0.123\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 63.77it/s]\n79it [00:07,  9.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:15 Train_Loss:228.721\tTrain RE:222.384\tTrain KL:6.337\nEpoch:15 Valid_Loss:2.860\tValid RE:2.710\tValid KL:0.120\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 66.15it/s]\n79it [00:07, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:16 Train_Loss:228.657\tTrain RE:222.312\tTrain KL:6.345\nEpoch:16 Valid_Loss:2.863\tValid RE:2.708\tValid KL:0.124\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 65.54it/s]\n79it [00:07, 10.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:17 Train_Loss:228.655\tTrain RE:222.313\tTrain KL:6.342\nEpoch:17 Valid_Loss:2.869\tValid RE:2.711\tValid KL:0.127\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:07, 69.44it/s]\n79it [00:07, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:18 Train_Loss:228.629\tTrain RE:222.277\tTrain KL:6.352\nEpoch:18 Valid_Loss:2.864\tValid RE:2.708\tValid KL:0.125\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 64.27it/s]\n79it [00:07,  9.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:19 Train_Loss:228.606\tTrain RE:222.250\tTrain KL:6.356\nEpoch:19 Valid_Loss:2.866\tValid RE:2.710\tValid KL:0.126\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 67.41it/s]\n79it [00:07, 10.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch:20 Train_Loss:228.728\tTrain RE:222.378\tTrain KL:6.350\nEpoch:20 Valid_Loss:2.863\tValid RE:2.707\tValid KL:0.125\nbeta: 1\n","output_type":"stream"},{"name":"stderr","text":"547it [00:08, 64.64it/s]\n61it [00:05, 10.68it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}